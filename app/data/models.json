{
    "data": [
        {
            "id": "anthropic/claude-haiku-4.5",
            "canonical_slug": "anthropic/claude-4.5-haiku-20251001",
            "hugging_face_id": "",
            "name": "Anthropic: Claude Haiku 4.5",
            "created": 1760547638,
            "description": "Claude Haiku 4.5 is Anthropic’s fastest and most efficient model, delivering near-frontier intelligence at a fraction of the cost and latency of larger Claude models. Matching Claude Sonnet 4’s performance across reasoning, coding, and computer-use tasks, Haiku 4.5 brings frontier-level capability to real-time and high-volume applications.\n\nIt introduces extended thinking to the Haiku line; enabling controllable reasoning depth, summarized or interleaved thought output, and tool-assisted workflows with full support for coding, bash, web search, and computer-use tools. Scoring >73% on SWE-bench Verified, Haiku 4.5 ranks among the world’s best coding models while maintaining exceptional responsiveness for sub-agents, parallelized execution, and scaled deployment.",
            "context_length": 200000,
            "architecture": {
                "modality": "text+image->text",
                "input_modalities": [
                    "image",
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "tokenizer": "Claude",
                "instruct_type": null
            },
            "pricing": {
                "prompt": "0.000001",
                "completion": "0.000005",
                "request": "0",
                "image": "0",
                "web_search": "0",
                "internal_reasoning": "0",
                "input_cache_read": "0.0000001",
                "input_cache_write": "0.00000125"
            },
            "top_provider": {
                "context_length": 200000,
                "max_completion_tokens": 64000,
                "is_moderated": true
            },
            "per_request_limits": null,
            "supported_parameters": [
                "include_reasoning",
                "max_tokens",
                "reasoning",
                "stop",
                "temperature",
                "tool_choice",
                "tools",
                "top_k",
                "top_p"
            ],
            "default_parameters": {
                "temperature": null,
                "top_p": null,
                "frequency_penalty": null
            }
        }
    ]
}